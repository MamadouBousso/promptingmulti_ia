# PromptingMulti_IA

Un assistant multi-IA intelligent d√©velopp√© avec Flask et une interface web moderne utilisant Tailwind CSS, int√©grant les APIs OpenAI (GPT-4o), Claude (Anthropic) et Groq (Llama) pour des r√©ponses intelligentes et comparatives.

## üìã Description

PromptingMulti_IA est une application web qui permet aux utilisateurs d'interagir avec plusieurs assistants IA via un formulaire textuel. L'application supporte trois fournisseurs d'IA majeurs et permet de comparer leurs r√©ponses en temps r√©el.

## üöÄ Fonctionnalit√©s

- **Interface Web Moderne** : Interface utilisateur responsive avec Tailwind CSS
- **Multi-IA Support** : Int√©gration OpenAI (GPT-4o), Claude (Anthropic) et Groq (Llama)
- **Comparaison en Temps R√©el** : Compare les r√©ponses des trois mod√®les simultan√©ment
- **Rendu Markdown** : Affichage riche avec support complet du formatage markdown
- **S√©lection de Mod√®les** : Choix sp√©cifique des mod√®les Llama pour Groq
- **Formulaire Interactif** : Zone de saisie pour les prompts textuels
- **API REST Compl√®te** : Endpoints pour chaque fournisseur d'IA
- **Gestion des Erreurs** : Interface utilisateur avec gestion des erreurs robuste
- **Indicateur de Chargement** : Feedback visuel pendant la g√©n√©ration
- **Architecture Modulaire** : Structure organis√©e avec s√©paration des responsabilit√©s
- **Environnement Virtuel** : Gestion des d√©pendances avec uv

## üõ†Ô∏è Technologies Utilis√©es

- **Backend** : Flask (Python)
- **Frontend** : HTML5, JavaScript, Tailwind CSS
- **IA** : 
  - OpenAI API (GPT-4o)
  - Anthropic API (Claude 3.5 Sonnet)
  - Groq API (Llama 3.1, Llama 4 Scout)
- **Markdown** : marked.js pour le rendu
- **Gestion des D√©pendances** : uv
- **Variables d'Environnement** : python-dotenv
- **Architecture** : Pattern MVC (Model-View-Controller)

## üìÅ Structure du Projet

```
promptingmulti_ia/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ application/     # Couche application (logique m√©tier)
‚îÇ   ‚îú‚îÄ‚îÄ domaine/         # Couche domaine (entit√©s et r√®gles m√©tier)
‚îÇ   ‚îî‚îÄ‚îÄ infrastructure/  # Couche infrastructure (base de donn√©es, API externes)
‚îÇ       ‚îú‚îÄ‚îÄ openai_client.py   # Client pour l'API OpenAI
‚îÇ       ‚îú‚îÄ‚îÄ claude_client.py   # Client pour l'API Claude
‚îÇ       ‚îî‚îÄ‚îÄ groq_client.py     # Client pour l'API Groq
‚îú‚îÄ‚îÄ templates/           # Templates HTML Flask
‚îÇ   ‚îî‚îÄ‚îÄ index.html       # Page principale de l'application
‚îú‚îÄ‚îÄ test/               # Tests unitaires et d'int√©gration
‚îú‚îÄ‚îÄ static/             # Fichiers statiques (CSS, JS, images)
‚îú‚îÄ‚îÄ app.py              # Point d'entr√©e de l'application Flask
‚îú‚îÄ‚îÄ env.example         # Exemple de variables d'environnement
‚îú‚îÄ‚îÄ pyproject.toml      # Configuration du projet et d√©pendances
‚îî‚îÄ‚îÄ README.md           # Documentation du projet
```

## üöÄ Installation et Configuration

### Pr√©requis

- Python 3.12+
- uv (gestionnaire de paquets Python)
- Cl√©s API pour au moins un des fournisseurs d'IA

### Installation

1. **Cloner le repository**
   ```bash
   git clone https://github.com/MamadouBousso/promptingmulti_ia.git
   cd promptingmulti_ia
   ```

2. **Initialiser l'environnement virtuel avec uv**
   ```bash
   uv init
   ```

3. **Installer les d√©pendances**
   ```bash
   uv pip install flask openai anthropic groq python-dotenv
   ```

4. **Configurer les variables d'environnement**
   ```bash
   # Copier le fichier d'exemple
   cp env.example .env
   
   # √âditer le fichier .env et ajouter vos cl√©s API
   # Voir la section Configuration des APIs ci-dessous
   ```

5. **Lancer l'application**
   ```bash
   python app.py
   ```

6. **Acc√©der √† l'application**
   Ouvrez votre navigateur et allez √† `http://localhost:8000`

## üîë Configuration des APIs

### Obtenir les cl√©s API

#### OpenAI (GPT-4o)
1. Allez sur [OpenAI Platform](https://platform.openai.com/)
2. Cr√©ez un compte ou connectez-vous
3. Allez dans la section "API Keys"
4. Cr√©ez une nouvelle cl√© API
5. Copiez la cl√© et ajoutez-la dans votre fichier `.env`

#### Claude (Anthropic)
1. Allez sur [Anthropic Console](https://console.anthropic.com/)
2. Cr√©ez un compte ou connectez-vous
3. Allez dans la section "API Keys"
4. Cr√©ez une nouvelle cl√© API
5. Copiez la cl√© et ajoutez-la dans votre fichier `.env`

#### Groq (Llama)
1. Allez sur [Groq Console](https://console.groq.com/)
2. Cr√©ez un compte ou connectez-vous
3. Allez dans la section "API Keys"
4. Cr√©ez une nouvelle cl√© API
5. Copiez la cl√© et ajoutez-la dans votre fichier `.env`

### Variables d'Environnement

Cr√©ez un fichier `.env` √† la racine du projet :

```env
# Configuration OpenAI (GPT-4o)
OPENAI_API_KEY=sk-your-actual-openai-api-key-here

# Configuration Anthropic (Claude)
ANTHROPIC_API_KEY=sk-ant-your-actual-anthropic-api-key-here

# Configuration Groq (Llama)
GROQ_API_KEY=gsk-your-actual-groq-api-key-here

# Configuration Flask
FLASK_ENV=development
FLASK_DEBUG=True
FLASK_PORT=8000
```

**Note** : Vous n'avez besoin que d'une seule cl√© API pour commencer. L'application fonctionnera avec les fournisseurs configur√©s.

## üéØ Utilisation

### Interface Utilisateur

L'interface se compose de :

1. **S√©lecteur d'IA** : Choisissez entre OpenAI, Claude, Groq ou comparer tous
2. **S√©lecteur de Mod√®le Groq** : Choisissez le mod√®le Llama sp√©cifique (visible uniquement pour Groq)
3. **Zone de saisie** : Champ de texte pour entrer vos questions/prompts
4. **Bouton d'envoi** : Pour soumettre votre requ√™te
5. **Zone de r√©ponse** : Affichage de la r√©ponse avec formatage markdown
6. **Zone de comparaison** : Affichage c√¥te √† c√¥te des r√©ponses des trois mod√®les
7. **Indicateur de chargement** : Animation pendant la g√©n√©ration
8. **Zone d'erreur** : Affichage des messages d'erreur

### Fonctionnement

1. **S√©lection du fournisseur** : Choisissez OpenAI, Claude, Groq ou "Comparer tous"
2. **S√©lection du mod√®le** : Si vous choisissez Groq, s√©lectionnez le mod√®le Llama
3. **Saisie du prompt** : Entrez votre question dans le champ de texte
4. **Envoi** : Cliquez sur "Envoyer" ou appuyez sur Entr√©e
5. **Affichage** : La r√©ponse s'affiche avec un formatage markdown complet

### Mod√®les Disponibles

#### Groq (Llama)
- **Llama 3.1 8B** : Mod√®le rapide et efficace
- **Llama 3.1 70B** : Mod√®le plus puissant
- **Llama 4 Scout 13B** : Mod√®le √©quilibr√©
- **Llama 4 Scout 17B** : Mod√®le performant
- **Llama 4 Scout 32B** : Mod√®le haute performance
- **Llama 4 Scout 65B** : Mod√®le ultra-performant

## üìù API Documentation

### Routes Disponibles

#### GET `/`
- **Description** : Page principale avec l'interface utilisateur
- **M√©thodes** : GET
- **R√©ponse** : Page HTML avec formulaire et interface

#### POST `/api/chat`
- **Description** : API endpoint pour les appels OpenAI
- **M√©thodes** : POST
- **Content-Type** : application/json
- **Param√®tres** :
  ```json
  {
    "prompt": "Votre question ici"
  }
  ```
- **R√©ponse** :
  ```json
  {
    "success": true,
    "text": "R√©ponse g√©n√©r√©e par OpenAI",
    "prompt": "Question originale"
  }
  ```

#### POST `/api/claude`
- **Description** : API endpoint pour les appels Claude
- **M√©thodes** : POST
- **Content-Type** : application/json
- **Param√®tres** :
  ```json
  {
    "prompt": "Votre question ici"
  }
  ```
- **R√©ponse** :
  ```json
  {
    "success": true,
    "text": "R√©ponse g√©n√©r√©e par Claude",
    "prompt": "Question originale",
    "model": "claude-3-5-sonnet-20241022",
    "provider": "anthropic"
  }
  ```

#### POST `/api/groq`
- **Description** : API endpoint pour les appels Groq
- **M√©thodes** : POST
- **Content-Type** : application/json
- **Param√®tres** :
  ```json
  {
    "prompt": "Votre question ici",
    "model": "llama3-8b-8192"
  }
  ```
- **R√©ponse** :
  ```json
  {
    "success": true,
    "text": "R√©ponse g√©n√©r√©e par Groq",
    "prompt": "Question originale",
    "model": "llama3-8b-8192",
    "provider": "groq"
  }
  ```

#### POST `/api/compare`
- **Description** : API endpoint pour comparer les trois fournisseurs
- **M√©thodes** : POST
- **Content-Type** : application/json
- **Param√®tres** :
  ```json
  {
    "prompt": "Votre question ici"
  }
  ```
- **R√©ponse** :
  ```json
  {
    "success": true,
    "prompt": "Question originale",
    "responses": {
      "openai": {
        "success": true,
        "text": "R√©ponse OpenAI"
      },
      "claude": {
        "success": true,
        "text": "R√©ponse Claude"
      },
      "groq": {
        "success": true,
        "text": "R√©ponse Groq"
      }
    }
  }
  ```

### Exemples d'utilisation de l'API

#### Test OpenAI
```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Explique-moi l'intelligence artificielle en 3 points"}'
```

#### Test Claude
```bash
curl -X POST http://localhost:8000/api/claude \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Quels sont les avantages du machine learning ?"}'
```

#### Test Groq
```bash
curl -X POST http://localhost:8000/api/groq \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Comment fonctionne un r√©seau de neurones ?", "model": "llama3-8b-8192"}'
```

#### Comparaison des trois
```bash
curl -X POST http://localhost:8000/api/compare \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Explique la diff√©rence entre l'IA et le machine learning"}'
```

## üîß Configuration

### Configuration Flask

L'application Flask est configur√©e avec :
- Mode debug activ√© pour le d√©veloppement
- Port par d√©faut : 8000 (configurable via FLASK_PORT)
- Templates dans le dossier `templates/`
- Gestion automatique des variables d'environnement

### Configuration des Mod√®les

#### OpenAI
- **Mod√®le par d√©faut** : gpt-4o
- **Max tokens** : 500
- **Temperature** : 0.7
- **Messages syst√®me** : Assistant vocal intelligent et utile

#### Claude
- **Mod√®le par d√©faut** : claude-3-5-sonnet-20241022
- **Max tokens** : 500
- **Temperature** : 0.7
- **Messages syst√®me** : Assistant vocal intelligent et utile

#### Groq
- **Mod√®le par d√©faut** : llama3-8b-8192
- **Max tokens** : 500
- **Temperature** : 0.7
- **Messages syst√®me** : Assistant vocal intelligent et utile

## üé® Formatage Markdown

L'application supporte le rendu complet du markdown avec :

- **Titres** : `# ## ###` ‚Üí Titres HTML format√©s
- **Listes** : `- * +` ‚Üí Listes √† puces visibles
- **Listes num√©rot√©es** : `1. 2.` ‚Üí Listes ordonn√©es
- **Gras** : `**texte**` ‚Üí Texte en gras
- **Italique** : `*texte*` ‚Üí Texte en italique
- **Code inline** : `` `code` `` ‚Üí Code avec fond gris
- **Blocs de code** : ```...``` ‚Üí Blocs de code format√©s
- **Liens** : `[texte](url)` ‚Üí Liens cliquables
- **Citations** : `> texte` ‚Üí Citations avec bordure
- **S√©parateurs** : `---` ‚Üí Lignes de s√©paration

## üß™ Tests

Pour ex√©cuter les tests (√† impl√©menter) :
```bash
# Tests unitaires
python -m pytest test/

# Tests d'int√©gration
python -m pytest test/integration/

# Tests des clients API
python -m pytest test/test_clients/
```

## üîÑ D√©veloppement

### Ajout de Nouvelles Fonctionnalit√©s

1. **Backend** : Ajoutez la logique dans `src/application/`
2. **Infrastructure** : Ajoutez les clients API dans `src/infrastructure/`
3. **Frontend** : Modifiez `templates/index.html`
4. **Tests** : Cr√©ez les tests correspondants dans `test/`

### Standards de Code

- **Python** : PEP 8
- **JavaScript** : ESLint (√† configurer)
- **HTML** : Validation W3C
- **CSS** : Tailwind CSS classes

### Architecture

Le projet suit une architecture en couches :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Templates     ‚îÇ ‚Üê Interface utilisateur
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   Application   ‚îÇ ‚Üê Logique m√©tier
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   Infrastructure‚îÇ ‚Üê Clients API externes
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üöÄ D√©ploiement

### Production

1. **Configuration WSGI**
   ```bash
   pip install gunicorn
   gunicorn -w 4 -b 0.0.0.0:8000 app:app
   ```

2. **Variables d'environnement**
   ```bash
   export FLASK_ENV=production
   export FLASK_DEBUG=0
   export OPENAI_API_KEY=your-production-key
   export ANTHROPIC_API_KEY=your-production-key
   export GROQ_API_KEY=your-production-key
   ```

### Docker (√† impl√©menter)

```dockerfile
FROM python:3.12-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["python", "app.py"]
```

## üîí S√©curit√©

- **Validation des entr√©es** : Tous les prompts sont valid√©s
- **Gestion des erreurs** : Erreurs API g√©r√©es gracieusement
- **Variables d'environnement** : Cl√©s API s√©curis√©es
- **CORS** : Configuration appropri√©e pour la production

## üìä Monitoring

- **Logs** : Logs d√©taill√©s des appels API
- **Erreurs** : Gestion et affichage des erreurs
- **Performance** : Temps de r√©ponse des APIs

## ü§ù Contribution

1. Fork le projet
2. Cr√©ez une branche feature (`git checkout -b feature/AmazingFeature`)
3. Committez vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

### Guidelines de Contribution

- Respectez les standards de code
- Ajoutez des tests pour les nouvelles fonctionnalit√©s
- Mettez √† jour la documentation
- Testez sur plusieurs fournisseurs d'IA

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.

## üë• Auteurs

- **Mamadou Bousso** - D√©veloppement initial et maintenance

## üôè Remerciements

- **Flask** pour le framework web
- **Tailwind CSS** pour les styles
- **OpenAI** pour l'API GPT-4o
- **Anthropic** pour l'API Claude
- **Groq** pour l'API Llama
- **marked.js** pour le rendu markdown
- **uv** pour la gestion des d√©pendances

## üìû Support

Pour toute question ou probl√®me :
- Ouvrez une issue sur GitHub
- Contactez l'√©quipe de d√©veloppement
- Consultez la documentation des APIs

## üîÆ Roadmap

- [ ] Support de nouveaux mod√®les d'IA
- [ ] Interface de chat en temps r√©el
- [ ] Historique des conversations
- [ ] Export des r√©ponses
- [ ] Interface d'administration
- [ ] M√©triques de performance
- [ ] Support multilingue
- [ ] Int√©gration de mod√®les locaux

---

**Version** : 2.0.0  
**Derni√®re mise √† jour** : 28 Juin 2025  
**Statut** : Production Ready avec support multi-IA
